{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> Stratified K-Fold Cross-Validation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset:\n",
      "    Data  Class\n",
      "0    -10      0\n",
      "1     -9      0\n",
      "2     -8      0\n",
      "3     -7      0\n",
      "4     -6      0\n",
      "5     -5      0\n",
      "6     -4      0\n",
      "7     -3      0\n",
      "8     -2      0\n",
      "9     -1      0\n",
      "10     0      1\n",
      "11     1      1\n",
      "12     2      1\n",
      "13     3      1\n",
      "14     4      1\n",
      "15     5      1\n",
      "16     6      1\n",
      "17     7      1\n",
      "18     8      1\n",
      "19     9      1\n",
      "20    10      1\n",
      "21    11      1\n",
      "22    12      1\n",
      "23    13      1\n",
      "24    14      1\n",
      "25    15      1\n",
      "26    16      1\n",
      "27    17      1\n",
      "28    18      1\n",
      "29    19      1\n",
      "30    20      1\n",
      "31    21      1\n",
      "32    22      1\n",
      "33    23      1\n",
      "34    24      1\n",
      "35    25      1\n",
      "36    26      1\n",
      "37    27      1\n",
      "38    28      1\n",
      "39    29      1\n",
      "40    30      1\n",
      "41    31      1\n",
      "42    32      1\n",
      "43    33      1\n",
      "44    34      1\n",
      "45    35      1\n",
      "46    36      1\n",
      "47    37      1\n",
      "48    38      1\n",
      "49    39      1\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "# Integers from -10 to 39\n",
    "data = np.array(list(range(-10, 0)) + list(range(0, 40)))\n",
    "\n",
    "# Class 0 for negatives, Class 1 for positives\n",
    "labels = np.array([0] * 10 + [1] * 40)  \n",
    "\n",
    "# Display the dataset\n",
    "df = pd.DataFrame({'Data': data, 'Class': labels})\n",
    "print(\"Full Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StratifiedKFold with 5 splits\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "   Test Set  Label Set\n",
      "0        -9          0\n",
      "1        -7          0\n",
      "2         3          1\n",
      "3         8          1\n",
      "4        11          1\n",
      "5        12          1\n",
      "6        24          1\n",
      "7        27          1\n",
      "8        30          1\n",
      "9        33          1\n",
      "Class Distribution in Test Set for Fold 1: {0: 2, 1: 8}\n",
      "\n",
      "Fold 2:\n",
      "   Test Set  Label Set\n",
      "0        -5          0\n",
      "1        -2          0\n",
      "2         6          1\n",
      "3        10          1\n",
      "4        15          1\n",
      "5        17          1\n",
      "6        18          1\n",
      "7        19          1\n",
      "8        28          1\n",
      "9        37          1\n",
      "Class Distribution in Test Set for Fold 2: {0: 2, 1: 8}\n",
      "\n",
      "Fold 3:\n",
      "   Test Set  Label Set\n",
      "0        -8          0\n",
      "1        -3          0\n",
      "2         7          1\n",
      "3        16          1\n",
      "4        20          1\n",
      "5        31          1\n",
      "6        32          1\n",
      "7        35          1\n",
      "8        38          1\n",
      "9        39          1\n",
      "Class Distribution in Test Set for Fold 3: {0: 2, 1: 8}\n",
      "\n",
      "Fold 4:\n",
      "   Test Set  Label Set\n",
      "0        -6          0\n",
      "1        -1          0\n",
      "2         0          1\n",
      "3         2          1\n",
      "4         4          1\n",
      "5         9          1\n",
      "6        21          1\n",
      "7        23          1\n",
      "8        25          1\n",
      "9        26          1\n",
      "Class Distribution in Test Set for Fold 4: {0: 2, 1: 8}\n",
      "\n",
      "Fold 5:\n",
      "   Test Set  Label Set\n",
      "0       -10          0\n",
      "1        -4          0\n",
      "2         1          1\n",
      "3         5          1\n",
      "4        13          1\n",
      "5        14          1\n",
      "6        22          1\n",
      "7        29          1\n",
      "8        34          1\n",
      "9        36          1\n",
      "Class Distribution in Test Set for Fold 5: {0: 2, 1: 8}\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the folds and display results\n",
    "fold_number = 1\n",
    "for train_index, test_index in skf.split(data, labels):\n",
    "    \n",
    "    # Get the training and test sets based on the fold indices\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Create a DataFrame to display the test set and its class labels for each fold\n",
    "    fold_df = pd.DataFrame({'Test Set': X_test, 'Label Set': y_test})\n",
    "    \n",
    "    # Display the fold number and corresponding test set and labels\n",
    "    print(f\"\\nFold {fold_number}:\")\n",
    "    print(fold_df)\n",
    "    \n",
    "    # Verify class distribution in the test set for each fold\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    class_distribution = dict(zip(unique, counts))\n",
    "    print(f\"Class Distribution in Test Set for Fold {fold_number}: {class_distribution}\")\n",
    "    \n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Bias Calculation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = {\n",
    "    'True_1': [10.0, 7.5, -3.0, 15.0, 2.0, 0.0, -5.0, 9.0, -2.0, 8.0],\n",
    "    'True_2': [5.0, 8.0, 12.0, -6.0, -1.0, 4.0, 10.0, 6.0, 3.0, -3.0],\n",
    "    'True_3': [-2.0, 0.5, 5.0, -3.0, 7.0, 2.0, -4.0, 0.0, 1.0, 4.0],\n",
    "    'True_4': [3.0, -4.0, 2.0, 10.0, -8.0, 1.0, -2.0, 3.0, -7.0, 0.0]\n",
    "}\n",
    "\n",
    "predicted_values = {\n",
    "    'Predicted_1': [11.0, 8.5, -2.0, 16.0, 3.0, 1.0, -4.0, 10.0, -1.0, 9.0],\n",
    "    'Predicted_2': [4.5, 7.5, 11.5, -6.5, -1.5, 3.5, 9.5, 5.5, 2.5, -3.5],\n",
    "    'Predicted_3': [-1.2, 1.3, 5.8, -2.2, 7.8, 2.8, -3.2, 0.8, 1.8, 4.8],\n",
    "    'Predicted_4': [1.8, -5.2, 0.8, 8.8, -9.2, -0.2, -3.2, 1.8, -8.2, -1.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bias for Predicted_1: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Euclidean norm for Predicted_1: 3.1622776601683795\n",
      "\n",
      "Bias for Predicted_2: [-0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5]\n",
      "Euclidean norm for Predicted_2: 1.5811388300841898\n",
      "\n",
      "Bias for Predicted_3: [0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8]\n",
      "Euclidean norm for Predicted_3: 2.529822128134703\n",
      "\n",
      "Bias for Predicted_4: [-1.2 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2 -1.2]\n",
      "Euclidean norm for Predicted_4: 3.7947331922020546\n"
     ]
    }
   ],
   "source": [
    "# Bias calculation and Euclidean norm\n",
    "for i in range(1, 5):\n",
    "    true_vals = np.array(true_values[f'True_{i}'])\n",
    "    predicted_vals = np.array(predicted_values[f'Predicted_{i}'])\n",
    "    \n",
    "    # Calculate the bias for each data point\n",
    "    bias = predicted_vals - true_vals\n",
    "\n",
    "    # Euclidean norm (L2 norm)  \n",
    "    norm = np.linalg.norm(bias)  \n",
    "    \n",
    "    print(f\"\\nBias for Predicted_{i}: {bias}\")\n",
    "    print(f\"Euclidean norm for Predicted_{i}: {norm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Impact of the Number of Folds (k)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) How Increasing or Decreasing the Number of Folds Affects Bias and Variance\n",
    "- Increasing the number of folds (larger k):\n",
    "        - Lower bias: The training set size per fold rises with the number of folds, so the model is trained on more data. As a result of the model learning from a bigger portion of the dataset, bias is typically reduced.\n",
    "        - Higher variance: The validation set becomes smaller as k rises. The model's performance estimations may vary more between folds when smaller validation sets are more susceptible to data volatility.\n",
    "- Decreasing the number of folds (smaller k):\n",
    "        - Higher bias: Since the model has less data to work with, it gets trained on a smaller subset of the data in each fold when there are fewer folds. This can result in a higher bias.\n",
    "        - Lower variance: The variance in performance estimates falls as the validation set gets bigger (with fewer folds). Because they are less susceptible to particular variances in the data, larger validation sets yield an evaluation that is more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Good Choices for the Number of Folds (k)\n",
    "\n",
    "i. A small dataset:\n",
    "- A larger k (e.g., 10 or more) is generally preferred for small datasets. This maximizes the training set size in each fold, allowing the model to learn from more data while still performing multiple evaluations. However, be cautious not to make k too large, as very small validation sets can lead to high variance in performance estimates.\n",
    "\n",
    "ii. A large dataset:\n",
    "- A smaller k (e.g., 5) is usually sufficient for large datasets. Each fold will still contain enough data for the model to learn effectively and provide stable validation results. Using a smaller k also reduces computational overhead, as fewer model training and evaluation cycles are needed.\n",
    "\n",
    "iii. An imbalanced dataset:\n",
    "- Stratified K-Fold with k=10 is often recommended. This ensures that the minority and majority classes are represented in each fold, helping to mitigate the issues caused by class imbalance. A higher number of folds ensures that each model is exposed to diverse representations of both classes during training and evaluation, leading to more reliable performance metrics, especially when dealing with minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'>Implementing Standard K-Fold (Without Stratification)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 Test Set (without stratification):\n",
      "Test Data: [ 3  7  9 15 16 20 22 29 35 38]\n",
      "Test Labels: [1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Fold 2 Test Set (without stratification):\n",
      "Test Data: [-7 -6 -4 -2  2  5 27 31 36 37]\n",
      "Test Labels: [0 0 0 0 1 1 1 1 1 1]\n",
      "\n",
      "Fold 3 Test Set (without stratification):\n",
      "Test Data: [-10  -5  -1   6  14  17  21  23  24  34]\n",
      "Test Labels: [0 0 0 1 1 1 1 1 1 1]\n",
      "\n",
      "Fold 4 Test Set (without stratification):\n",
      "Test Data: [-9 -8  1 11 13 19 25 26 30 33]\n",
      "Test Labels: [0 0 1 1 1 1 1 1 1 1]\n",
      "\n",
      "Fold 5 Test Set (without stratification):\n",
      "Test Data: [-3  0  4  8 10 12 18 28 32 39]\n",
      "Test Labels: [0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create the KFold object without stratification\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through the folds and display test sets\n",
    "fold_number = 1\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_test, y_test = data[test_index], labels[test_index]\n",
    "    \n",
    "    # Display test set for each fold\n",
    "    print(f\"\\nFold {fold_number} Test Set (without stratification):\")\n",
    "    print(f\"Test Data: {X_test}\")\n",
    "    print(f\"Test Labels: {y_test}\")\n",
    "    \n",
    "    fold_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
